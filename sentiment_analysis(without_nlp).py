# -*- coding: utf-8 -*-
"""SENTIMENT_ANALYSIS(Without_NLP).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wWLze2RciK3M93Ys6sk-DQ2WnPbPwBMP
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/amazon.csv")
df

df.head()

df.info()

df.describe()

df.columns

df.isnull().sum()

df["discounted_price"]

df.shape

df.columns.tolist()

df.isnull().sum()

df.nunique()

# Step 2: Sample training data for demo (Replace this with your full dataset)
sample_data = pd.DataFrame({
    'reviewText': [
        "i hate it",
        "average",
        "i like it",
        "I love this product!",
        "i love it",
        "Worst experience ever.",
        "It's okay, not bad",
        "Very useful and great quality",
        "Disappointed with the item",
        "Average item, nothing special",
        "It's okay, not bad",
        "Very useful and great quality",
        "Average item, nothing special",
        "Absolutely fantastic! Highly recommend it.",
        "Terrible, waste of money.",
        "Not what I expected, but usable.",
        "Excellent build and performance.",
        "Poor packaging, item arrived broken.",
        "Satisfied with the purchase",
        "Nothing great, just average.",
        "Best purchase I've made this year.",
        "Would not buy again.",
        "This is decent for the price.",
        "Horrible experience, avoid it.",
        "Love the features and easy to use!",
        "I love this!",
        "Hated it",
        "It was okay",
        "Amazing experience",
        "Worst product",
        "Not bad",
        "Very helpful",
        "Would not recommend",
        "Loved the quality",
        "Disappointed",
        "Average",
        "Superb!",
        "Terrible",
        "Happy with it",
        "It was horrible",
        "Great performance",
        "Could be better",
        "Trash item",
        "Not satisfied",
        "Awesome product",
        "So-so",
        "Loved it",
        "Donâ€™t like it",
        "Perfect!",
        "Not impressed",
        "Good enough",
        "Awful",
        "Brilliant!",
        "Waste of money",
        "Best one ever"


    ],
    'sentiment': ["Negative","Neutral","Positive","Positive","Positive" ,"Negative", "Neutral", "Positive", "Negative", "Neutral","Neutral","Positive",
        "Neutral", "Positive", "Negative", "Neutral",
        "Positive", "Negative", "Positive", "Neutral",
        "Positive", "Negative", "Neutral", "Negative",
        "Positive","Positive", "Negative", "Neutral", "Positive", "Negative", "Neutral",
        "Positive", "Negative", "Positive", "Negative", "Neutral", "Positive",
        "Negative", "Positive", "Negative", "Positive", "Neutral", "Negative",
        "Negative", "Positive", "Neutral", "Positive", "Negative", "Positive",
        "Neutral", "Positive", "Negative", "Positive", "Negative", "Positive"

]
})

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')
X = vectorizer.fit_transform(sample_data['reviewText'])
y = sample_data['sentiment']

# Step 3: Train-Test Split (Stratified)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

#Step 4: Model Training (Logistic Regression)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

clf = LogisticRegression(C=1.0, max_iter=1000)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"âœ… Accuracy: {acc*100:.2f}%")

#Step 5: Plot Confusion Matrix

cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
disp.plot(cmap='Blues')
plt.title("Final Model - Confusion Matrix")
plt.grid(False)
plt.show()

# Regression (Predict sentiment score)
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Encode sentiments for regression
le = LabelEncoder()
y_encoded = le.fit_transform(sample_data["sentiment"])  # 0=Negative, 1=Neutral, 2=Positive

# Same split for encoded values
_, _, y_train_r, y_test_r = train_test_split(
    X, y_encoded, test_size=0.2, stratify=y, random_state=42
)

# Train regression model
reg = LinearRegression()
reg.fit(X_train, y_train_r)
y_pred_r = reg.predict(X_test)

# MSE
mse = mean_squared_error(y_test_r, y_pred_r)
print(f"ðŸ“ˆ Regression Mean Squared Error: {mse:.2f}")

# Plot: Actual vs Predicted
import matplotlib.pyplot as plt
plt.figure(figsize=(8, 5))
plt.plot(range(len(y_test_r)), y_test_r, label='Actual', marker='o')
plt.plot(range(len(y_pred_r)), y_pred_r, label='Predicted', marker='x', color='red')
plt.title("Regression: Actual vs Predicted Sentiment Scores")
plt.xlabel("Sample Index")
plt.ylabel("Sentiment (0=Neg, 1=Neu, 2=Pos)")
plt.legend()
plt.grid(True)
plt.show()

#clustering(k means)
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# Use full vectorized data (no split needed)
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)

# PCA for 2D visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

# Plot clusters
plt.figure(figsize=(8, 5))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap="viridis", s=70)
plt.title("Clustering (KMeans) of Reviews")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.colorbar(label="Cluster ID")
plt.grid(True)
plt.show()

# Show sample with cluster labels
sample_data["cluster"] = clusters
print(sample_data[["reviewText", "sentiment", "cluster"]].head(10))

# Step 3: Vectorize training data
vectorizer = CountVectorizer(analyzer='char', lowercase=False)
X = vectorizer.fit_transform(sample_data["reviewText"])
y = sample_data["sentiment"]

# Step 4: Train classification model
model = LogisticRegression()
model.fit(X, y)

# Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# Step 5: Take user input
user_input = input(" Enter your review: ")

# Step 6: Vectorize and predict sentiment
X_input = vectorizer.transform([user_input])
predicted_sentiment = model.predict(X_input)[0]
print(f"\n Predicted Sentiment: {predicted_sentiment}")

# Step 7: Prepare binary bar data
bar_data = {
    "Positive": 1 if predicted_sentiment == "Positive" else 0,
    "Neutral": 1 if predicted_sentiment == "Neutral" else 0,
    "Negative": 1 if predicted_sentiment == "Negative" else 0
}

plt.figure(figsize=(6, 4))
plt.bar(bar_data.keys(), bar_data.values(), color=['green', 'blue', 'red'])
plt.title("Predicted Sentiment")
plt.xlabel("Sentiment")
plt.ylabel("Confidence (1 = Predicted)")
plt.ylim(0, 1.2)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()





